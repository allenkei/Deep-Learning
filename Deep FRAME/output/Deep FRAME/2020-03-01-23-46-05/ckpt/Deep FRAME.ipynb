{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep FRAME.ipynb","provenance":[],"authorship_tag":"ABX9TyOJ/nQZu4vN60yZfMx7IY26"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"kdoTQHrr0YM-","colab_type":"code","outputId":"35a85f21-23e4-4457-eaf1-7ab3faa6229d","executionInfo":{"status":"error","timestamp":1583106266662,"user_tz":480,"elapsed":126689,"user":{"displayName":"Allen Kei","photoUrl":"","userId":"01162356375273084921"}},"colab":{"base_uri":"https://localhost:8080/","height":739}},"source":["import os\n","import random\n","import logging\n","import sys\n","import shutil\n","import argparse\n","import datetime\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torchvision import datasets, transforms\n","import torchvision.utils as vutils\n","from google.colab import drive \n","\n","\n","def opts(output_dir):\n","    args = argparse.Namespace()\n","\n","    args.gpu = 1\n","    args.num_epoch = 1001\n","    args.img_size = 224\n","\n","    args.data_path = '/content/drive/My Drive/Colab Notebooks/code/data/beehive'\n","    args.output_dir = '{}/images'.format(output_dir)\n","    args.log_dir = '{}/log'.format(output_dir)\n","    args.ckpt_dir = '{}/ckpt'.format(output_dir)\n","\n","    args.num_chains = 1\n","    args.sigma = 1.0\n","    args.langevin_step_num = 10\n","    # TODO tune step size\n","    args.langevin_step_size = 0.1\n","    # TODO tune learning rate\n","    args.lr = [0.005, 0.01, 0.00001, 0.03, 0.005, 0.0003]\n","    args.beta1 = 0.5\n","\n","    args.debug_grad_norm = False\n","\n","    return args\n","\n","\n","class Descriptor(nn.Module):\n","    def __init__(self):\n","        super(Descriptor, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 100, 15, 1, 4, bias=True)\n","        self.conv2 = nn.Conv2d(100, 64, 5, 1, 2, bias=True)\n","        #self.conv3 = nn.Conv2d(64, 30, 3, 1, 2, bias=True)\n","\n","    def forward(self, x):\n","        # TODO adjust the model structure\n","        x = nn.functional.max_pool2d(nn.functional.relu(self.conv1(x)), (3,3))\n","        x = nn.functional.relu(self.conv2(x))\n","        #x = nn.functional.relu(self.conv3(x))\n","\n","        return x.squeeze()\n","\n","\n","class Model(nn.Module):\n","    def __init__(self, logger, opts, device):\n","        super(Model, self).__init__()\n","        self.logger = logger\n","        self.opts = opts\n","        self.device = device\n","\n","    def langevin(self, descriptor, x):\n","        eps = self.opts.langevin_step_size\n","        s = self.opts.sigma\n","        for i in range(self.opts.langevin_step_num):\n","            x = Variable(x.data, requires_grad=True)\n","            x_feature = descriptor(x)\n","            x_feature.backward(torch.ones_like(x_feature)) # a tensor filled with 1 with the same size as x_feature\n","            noise = torch.randn_like(x).to(self.device)\n","            x.data += eps * eps / 2 * x.grad - eps * eps / 2 / s / s * x + eps * noise\n","        return x\n","\n","    def train(self):\n","        dataset = IgnoreLabelDataset(datasets.ImageFolder(root=self.opts.data_path,\n","                                       transform=transforms.Compose([\n","                                           transforms.Resize(self.opts.img_size),\n","                                           transforms.ToTensor()\n","                                       ])))\n","\n","        descriptor = Descriptor().to(self.device)\n","        im = dataset[0].unsqueeze(0).to(self.device)\n","        im_mean = create_mean_image(im).to(self.device)\n","        num_filters = get_num_filters(descriptor, im.shape, self.device)\n","\n","        sample_pos = normalize_image(im, im_mean)\n","        sample_neg = torch.zeros_like(sample_pos)\n","\n","        save_images(sample_pos + im_mean, '{}/data.png'.format(self.opts.output_dir))\n","\n","        for epoch in range(self.opts.num_epoch):\n","\n","            sample_neg = self.langevin(descriptor, sample_neg)\n","\n","            sample_pos_feature = descriptor(sample_pos)\n","            sample_neg_feature = descriptor(sample_neg)\n","\n","            en_pos = sample_pos_feature.sum()\n","            en_neg = sample_neg_feature.sum()\n","            loss = en_pos - en_neg\n","\n","            descriptor.zero_grad()\n","            loss.backward()\n","            grad_norm = 0.\n","            for p, n_f, lr in zip(descriptor.parameters(), num_filters, self.opts.lr):\n","                params_norm = torch.norm(p.data)\n","                grad = p.grad.data / n_f\n","                grad_norm_per_layer = torch.norm(grad)\n","\n","                p.data += grad * lr\n","                if (self.opts.debug_grad_norm):\n","                    self.logger.info('layer param norm = {:>18.4f} original grad norm = {:>18.4f}'.format(params_norm, grad_norm_per_layer))\n","\n","                grad_norm += grad_norm_per_layer\n","\n","            self.logger.info('{:>5d} loss={:>18.2f} en(pos)={:>18.2f} en(neg)={:>18.2f} norm(grad)={:>18.6f}'.format(epoch, loss, en_pos.sum(), en_neg.sum(), grad_norm))\n","\n","            if epoch % 100 == 0:\n","                # self.logger.info('max= {:>10.2f}, min= {:>10.2f}'.format(torch.max(sample_neg + im_mean), torch.min(sample_neg + im_mean)))\n","                save_images(rescaleSynthesizedImage(sample_neg + im_mean), '{}/{}.png'.format(self.opts.output_dir, epoch))\n","\n","            if epoch > 0 and epoch % 1000 == 0:\n","                torch.save(descriptor.state_dict(), self.opts.ckpt_dir + '/descriptor_{}.pth'.format(epoch))\n","\n","        saveConv1Filters(self.opts.ckpt_dir, descriptor)\n","\n","\n","def rescaleSynthesizedImage(img):\n","    img[img<0] = 0\n","    img[img>255] = 255\n","    return img\n","\n","\n","class IgnoreLabelDataset(torch.utils.data.Dataset):\n","    def __init__(self, orig):\n","        self.orig = orig\n","\n","    def __getitem__(self, index):\n","        return self.orig[index][0]\n","\n","    def __len__(self):\n","        return len(self.orig)\n","\n","\n","def create_mean_image(im):\n","    im_mean = torch.zeros(im.shape)\n","    means = im.mean(-1).mean(-1)[0]\n","    im_mean[:, 0, :, :] = means[0] * 255\n","    im_mean[:, 1, :, :] = means[1] * 255\n","    im_mean[:, 2, :, :] = means[2] * 255\n","    # im_mean[:, 0, :, :] = 123.680\n","    # im_mean[:, 1, :, :] = 116.779\n","    # im_mean[:, 2, :, :] = 103.939\n","    return im_mean\n","\n","\n","def get_num_filters(net, shape, device):\n","    x = torch.zeros(shape).to(device)\n","    num_filters = torch.zeros(len(list(net.parameters())), dtype=torch.float).to(device)\n","    for param in net.parameters():\n","        print(type(param.data), param.size())\n","    for c in net.children():\n","        print(c)\n","    for i, c in enumerate(net.children()):\n","        x = c(x)\n","        num_filters[i*2+0] = x.shape[2] * x.shape[3]\n","        num_filters[i*2+1] = x.shape[2] * x.shape[3]\n","        # num_filters[i] = x.shape[2] * x.shape[3]\n","    return num_filters\n","\n","\n","def normalize_image(im, mean_im):\n","    im.data *= 255\n","    im.data -= mean_im.data\n","    return im\n","\n","\n","def grad_norm(net):\n","    return torch.sqrt(sum(torch.sum(p.grad ** 2) for p in net.parameters()))\n","\n","\n","def set_seed(seed):\n","    if seed is None:\n","        seed = random.randint(1, 10000)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","    return seed\n","\n","\n","def set_cudnn():\n","    if torch.cuda.is_available():\n","        torch.backends.cudnn.benchmark = True\n","\n","\n","def set_gpu(device):\n","    if torch.cuda.is_available():\n","        torch.cuda.set_device(device)\n","        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","        os.environ['CUDA_VISIBLE_DEVICES'] = str(device)\n","\n","\n","def save_images(img, path):\n","    vutils.save_image(img, path, normalize=True, nrow=1)\n","\n","\n","def copy_source(file, output_dir):\n","    shutil.copyfile(file, os.path.join(output_dir, os.path.basename(file)))\n","\n","\n","def get_output_dir(exp_id):\n","    t = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n","    output_dir = os.path.join('/content/drive/My Drive/Colab Notebooks/code/output/{}'.format(exp_id), t)\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","    return output_dir\n","\n","\n","def setup_logging(name, output_dir, console=True):\n","    log_format = logging.Formatter(\"%(asctime)s : %(message)s\")\n","    logger = logging.getLogger(name)\n","    logger.handlers = []\n","    output_file = os.path.join(output_dir, 'output.log')\n","    file_handler = logging.FileHandler(output_file)\n","    file_handler.setFormatter(log_format)\n","    logger.addHandler(file_handler)\n","    if console:\n","        console_handler = logging.StreamHandler(sys.stdout)\n","        console_handler.setFormatter(log_format)\n","        logger.addHandler(console_handler)\n","    logger.setLevel(logging.INFO)\n","    return logger\n","\n","\n","def main():\n","    drive.mount('/content/drive')\n","    __file__ = '/content/drive/My Drive/Colab Notebooks/code/Deep FRAME.ipynb'\n","    exp_id = os.path.splitext(os.path.basename(__file__))[0]\n","    output_dir = get_output_dir(exp_id)\n","    opt = opts(output_dir)\n","\n","    set_seed(1)\n","    set_cudnn()\n","    set_gpu(opt.gpu)\n","\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","    if not os.path.exists(opt.ckpt_dir):\n","        os.makedirs(opt.ckpt_dir)\n","    if not os.path.exists(opt.output_dir):\n","        os.makedirs(opt.output_dir)\n","    if not os.path.exists(opt.log_dir):\n","        os.makedirs(opt.log_dir)\n","\n","    logger = setup_logging('main', opt.log_dir)\n","    copy_source(__file__, opt.ckpt_dir)\n","\n","    model = Model(logger, opt, device)\n","    model.train()\n","\n","\n","def loadModel(dir, filename):\n","    descriptor = Descriptor()\n","    descriptor.load_state_dict(torch.load(os.path.join(dir, filename)))\n","    return descriptor\n","\n","def saveConv1Filters(dir, descriptor, filename='layer1_filters.png'):\n","    weights = list(descriptor.parameters())[0].data\n","    vutils.save_image(weights[0:64, :, :, :], os.path.join(dir, filename), normalize=True)\n","\n","\n","if __name__ == '__main__':\n","    main()\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","<class 'torch.Tensor'> torch.Size([100, 3, 15, 15])\n","<class 'torch.Tensor'> torch.Size([100])\n","<class 'torch.Tensor'> torch.Size([64, 100, 5, 5])\n","<class 'torch.Tensor'> torch.Size([64])\n","Conv2d(3, 100, kernel_size=(15, 15), stride=(1, 1), padding=(4, 4))\n","Conv2d(100, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","2020-03-01 23:42:29,729 :     0 loss=        3215346.25 en(pos)=        3239952.00 en(neg)=          24605.75 norm(grad)=        862.998230\n","2020-03-01 23:42:38,050 :     1 loss=        8229911.00 en(pos)=        8270056.50 en(neg)=          40145.53 norm(grad)=       1515.146362\n","2020-03-01 23:42:46,149 :     2 loss=       18715064.00 en(pos)=       18781098.00 en(neg)=          66034.88 norm(grad)=       2766.270508\n","2020-03-01 23:42:54,333 :     3 loss=       36625044.00 en(pos)=       36827816.00 en(neg)=         202770.91 norm(grad)=       4564.770996\n","2020-03-01 23:43:02,651 :     4 loss=       67756720.00 en(pos)=       68730008.00 en(neg)=         973290.44 norm(grad)=       6997.081055\n","2020-03-01 23:43:10,813 :     5 loss=      124581368.00 en(pos)=      128878856.00 en(neg)=        4297488.50 norm(grad)=      10239.147461\n","2020-03-01 23:43:19,026 :     6 loss=      228326064.00 en(pos)=      245969792.00 en(neg)=       17643724.00 norm(grad)=      14289.421875\n","2020-03-01 23:43:27,220 :     7 loss=      402911040.00 en(pos)=      471957824.00 en(neg)=       69046784.00 norm(grad)=      18766.285156\n","2020-03-01 23:43:35,389 :     8 loss=      633328000.00 en(pos)=      884197632.00 en(neg)=      250869616.00 norm(grad)=      21942.277344\n","2020-03-01 23:43:43,432 :     9 loss=      753324864.00 en(pos)=     1532617472.00 en(neg)=      779292608.00 norm(grad)=      20396.322266\n","2020-03-01 23:43:51,460 :    10 loss=      442018816.00 en(pos)=     2274694912.00 en(neg)=     1832676096.00 norm(grad)=      12825.387695\n","2020-03-01 23:43:59,784 :    11 loss=     -261114880.00 en(pos)=     2667841024.00 en(neg)=     2928955904.00 norm(grad)=      11697.007812\n","2020-03-01 23:44:07,881 :    12 loss=     -657071104.00 en(pos)=     2390267392.00 en(neg)=     3047338496.00 norm(grad)=      17550.591797\n","2020-03-01 23:44:16,067 :    13 loss=     -430083328.00 en(pos)=     1781436416.00 en(neg)=     2211519744.00 norm(grad)=      15122.833008\n","2020-03-01 23:44:24,256 :    14 loss=     -125348608.00 en(pos)=     1386418688.00 en(neg)=     1511767296.00 norm(grad)=      14934.910156\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-7a5e17aa8c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-7a5e17aa8c45>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-7a5e17aa8c45>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0msample_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlangevin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0msample_pos_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-7a5e17aa8c45>\u001b[0m in \u001b[0;36mlangevin\u001b[0;34m(self, descriptor, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mx_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mx_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# a tensor filled with 1 with the same size as x_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}